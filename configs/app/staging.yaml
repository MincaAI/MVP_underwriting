environment: staging
debug: false
log_level: DEBUG

# Database (AWS RDS PostgreSQL with pgvector)
database:
  host: ${DB_HOST}
  port: 5432
  name: ${DB_NAME}
  user: ${DB_USER}
  password: ${DB_PASSWORD}
  pool_size: 10
  max_overflow: 15

# Redis (AWS ElastiCache)
redis:
  host: ${REDIS_HOST}
  port: 6379
  db: 0
  password: ${REDIS_PASSWORD}
  max_connections: 20

# Storage (AWS S3)
storage:
  provider: s3
  endpoint: https://s3.${AWS_REGION}.amazonaws.com
  access_key: ${AWS_ACCESS_KEY_ID}
  secret_key: ${AWS_SECRET_ACCESS_KEY}
  bucket_raw: ${S3_BUCKET_RAW}
  bucket_exports: ${S3_BUCKET_EXPORTS}
  region: ${AWS_REGION}

# Message Queues (AWS SQS)
queues:
  extractor: "${PROJECT_NAME}-staging-extractor"
  codifier: "${PROJECT_NAME}-staging-codifier"
  transform: "${PROJECT_NAME}-staging-transform"
  exporter: "${PROJECT_NAME}-staging-exporter"

# API Configuration
api:
  host: "0.0.0.0"
  port: 8000
  cors_origins:
    - "https://staging.${DOMAIN}"
    - "http://localhost:3000"
  jwt_secret: ${JWT_SECRET}

# ML Configuration
ml:
  models:
    embedding: "sentence-transformers/all-MiniLM-L6-v2"
    reranker: "cross-encoder/ms-marco-MiniLM-L-2-v2"
  
  thresholds:
    auto_accept: 0.80
    review_required: 0.65
    
  batch_sizes:
    codification: 50
    extraction: 100

# Feature Flags
features:
  enable_auto_codify: true
  enable_batch_processing: true
  enable_audit_logging: true
  enable_file_validation: true
  enable_real_time_updates: true

# File Processing
file_processing:
  max_file_size: 52428800  # 50MB
  allowed_extensions:
    - .xlsx
    - .xls
    - .csv
    - .pdf
    - .eml
  
  extraction_timeout: 300  # 5 minutes
  processing_timeout: 600  # 10 minutes

# Monitoring
monitoring:
  enable_metrics: true
  metrics_port: 9090
  enable_tracing: true
  
# Staging specific
staging:
  auto_reload: false
  mock_external_services: false
  seed_data: true
  enable_debug_routes: true
